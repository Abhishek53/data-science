import openai  # Assuming you're using OpenAI's GPT API. Replace with appropriate library if using a different LLM.

def chat_with_llm(prompt):
    """
    This function sends the user's prompt to the LLM and returns the generated response.
    
    Args:
        prompt (str): The user's input to the LLM.
    
    Returns:
        str: The response generated by the LLM.
    """
    response = openai.Completion.create(
        engine="text-davinci-003",  # Update this with your preferred model
        prompt=prompt,
        max_tokens=150,  # Adjust as needed
        temperature=0.7,  # Adjust for creativity vs. precision
        n=1,  # Number of responses to generate
        stop=None,  # You can set a stop sequence if needed
    )
    return response.choices[0].text.strip()

# You can add other utility functions here as needed.
